\chapter{\abstractname}

%TODO: Abstract
Human languages evolve as a trade-off between expressiveness and efficiency, constrained by the cognitive and social demands of communication. 
Constructed languages (ConLangs), in contrast, allow for deliberate design choices that can potentially optimize these trade-offs. This thesis 
investigates whether Large Language Models (LLMs), trained on vast corpora of natural language, can aid in the systematic construction of minimal 
languages that retain communicative efficacy. To explore this, we design a modular language generation and evaluation pipeline, encompassing 
phonology, phonotactics, grammar, and vocabulary. The generated languages are assessed using both traditional NLP evaluation metrics (BLEU, ROUGE, METEOR), 
as well as language model perplexity and reading comprehension scores on the RACE-C dataset. We also analyze how well these languages conform to linguistic 
properties such as Zipf's Law. The results suggest that it is possible to simplify several linguistic subsystems, such as reducing phoneme count or 
grammatical complexity without significantly degrading performance on comprehension or translation tasks. This indicates that LLMs can indeed 
provide valuable insights into the design of compact, interpretable, and efficient constructed languages.